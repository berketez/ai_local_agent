#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
TarayÄ±cÄ± AjanÄ± Ã‡alÄ±ÅŸtÄ±rma BetiÄŸi

Bu betik, tarayÄ±cÄ± ajanÄ±nÄ±n "DÃ¼ÅŸÃ¼n-AraÅŸtÄ±r-GÃ¶zlemle-Eyleme GeÃ§" dÃ¶ngÃ¼sÃ¼nÃ¼
kullanarak web Ã¼zerinde akÄ±llÄ± araÅŸtÄ±rmalar yapmasÄ±nÄ± saÄŸlar.

Yerel LLM modellerini (Ollama veya Local AI) kullanarak Ã§alÄ±ÅŸÄ±r,
herhangi bir API anahtarÄ± gerektirmez.
"""

import os
import sys
import argparse
import subprocess
import requests
from planner_executor import BrowserAgent

def check_ollama_running():
    """Ollama'nÄ±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et."""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        return response.status_code == 200
    except:
        return False

def start_ollama_if_needed():
    """Ollama Ã§alÄ±ÅŸmÄ±yorsa baÅŸlat."""
    if not check_ollama_running():
        print("Ollama Ã§alÄ±ÅŸmÄ±yor. BaÅŸlatÄ±lÄ±yor...")
        try:
            # Arkaplanda Ollama'yÄ± baÅŸlat
            subprocess.Popen(["ollama", "serve"], 
                           stdout=subprocess.DEVNULL, 
                           stderr=subprocess.DEVNULL)
            
            # BaÅŸlamasÄ±nÄ± bekle
            import time
            for _ in range(5):  # 5 saniye bekle
                time.sleep(1)
                if check_ollama_running():
                    print("Ollama baÅŸlatÄ±ldÄ±!")
                    return True
            
            print("Ollama baÅŸlatÄ±lamadÄ±. Manuel olarak 'ollama serve' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return False
        except Exception as e:
            print(f"Ollama baÅŸlatÄ±lÄ±rken hata: {e}")
            print("Ollama yÃ¼klÃ¼ olmayabilir. Kurulum iÃ§in: https://ollama.com/download")
            return False
    return True

def list_available_models():
    """KullanÄ±labilir yerel modelleri listele."""
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = [model["name"] for model in response.json().get("models", [])]
            return models
        return []
    except:
        return []

def main():
    """Ana program fonksiyonu."""
    parser = argparse.ArgumentParser(description="TarayÄ±cÄ± AjanÄ±nÄ± Ã§alÄ±ÅŸtÄ±r (Yerel LLM ile)")
    parser.add_argument("--query", "-q", type=str, help="AraÅŸtÄ±rÄ±lacak sorgu")
    parser.add_argument("--model", "-m", type=str, default="llama2", 
                      help="KullanÄ±lacak yerel model adÄ± (varsayÄ±lan: llama2)")
    parser.add_argument("--steps", "-s", type=int, default=8, 
                      help="Maksimum adÄ±m sayÄ±sÄ± (varsayÄ±lan: 8)")
    parser.add_argument("--verbose", "-v", action="store_true",
                      help="DetaylÄ± Ã§Ä±ktÄ± gÃ¶ster")
    parser.add_argument("--list-models", "-l", action="store_true",
                      help="KullanÄ±labilir modelleri listele ve Ã§Ä±k")
    
    args = parser.parse_args()
    
    # Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin ol
    if not start_ollama_if_needed():
        return 1
    
    # Modelleri listele ve Ã§Ä±k
    if args.list_models:
        models = list_available_models()
        if models:
            print("KullanÄ±labilir modeller:")
            for model in models:
                print(f"  - {model}")
        else:
            print("HiÃ§ model bulunamadÄ±. 'ollama pull llama2' komutu ile model indirebilirsiniz.")
        return 0
    
    # Sorguyu komut satÄ±rÄ±ndan veya kullanÄ±cÄ± girdisinden al
    query = args.query
    if not query:
        query = input("Soru veya araÅŸtÄ±rma konusunu yazÄ±n: ")
    
    # AjanÄ± baÅŸlat
    agent = BrowserAgent(model=args.model)
    agent.max_steps = args.steps
    
    print(f"\nğŸ” AraÅŸtÄ±rÄ±lÄ±yor: {query}")
    print(f"ğŸ¤– Model: {args.model}")
    print("â³ Bu iÅŸlem biraz zaman alabilir...\n")
    
    # AjanÄ± Ã§alÄ±ÅŸtÄ±r ve sonucu al
    if args.verbose:
        print("ğŸ”„ AdÄ±mlar baÅŸlatÄ±lÄ±yor...\n")
    
    result = agent.run(query)
    
    # Sonucu gÃ¶ster
    print("\nğŸ“Š AraÅŸtÄ±rma Sonucu:")
    print("-" * 50)
    print(result)
    print("-" * 50)
    
    # EÄŸer detaylÄ± mod aktifse, adÄ±m kayÄ±tlarÄ±nÄ± gÃ¶ster
    if args.verbose and agent.scratchpad:
        print("\nğŸ” AraÅŸtÄ±rma AdÄ±mlarÄ±:")
        for i, item in enumerate(agent.scratchpad):
            if item["role"] == "assistant" and "THOUGHT:" in item["content"]:
                thought = item["content"].split("THOUGHT:")[1].split("ACTION:")[0].strip() if "THOUGHT:" in item["content"] else ""
                action = item["content"].split("ACTION:")[1].strip() if "ACTION:" in item["content"] else ""
                print(f"\nAdÄ±m {i//2 + 1}:")
                if thought:
                    print(f"  DÃ¼ÅŸÃ¼nce: {thought[:100]}...")
                if action:
                    print(f"  Eylem: {action}")
    
    # Her adÄ±mdan sonra ÅŸunu ekleyelim:
    if len(agent.scratchpad) > 2:
        agent.scratchpad.append({"role": "system", "content": "Devam et, sonuca ulaÅŸmadÄ±n! Daha fazla araÅŸtÄ±r ve bilgileri analiz et."})
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 